%% Generated by Sphinx.
\def\sphinxdocclass{jupyterBook}
\documentclass[letterpaper,10pt,english]{jupyterBook}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}
%% memoir class requires extra handling
\makeatletter\@ifclassloaded{memoir}
{\ifdefined\memhyperindexfalse\memhyperindexfalse\fi}{}\makeatother

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{FreeSerif}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Italic,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldItalic
]
\setsansfont{FreeSans}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]
\setmonofont{FreeMono}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]


\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=0,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{1. Introduction}}

\usepackage{sphinxmessages}



        % Start of preamble defined in sphinx-jupyterbook-latex %
         \usepackage[Latin,Greek]{ucharclasses}
        \usepackage{unicode-math}
        % fixing title of the toc
        \addto\captionsenglish{\renewcommand{\contentsname}{Contents}}
        \hypersetup{
            pdfencoding=auto,
            psdextra
        }
        % End of preamble defined in sphinx-jupyterbook-latex %
        

\title{Data Science - A practical Approach}
\date{Sep 24, 2021}
\release{}
\author{Lorenz Feyen}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{foreword::doc}}


\sphinxAtStartPar
this is a foreword

\sphinxAtStartPar
pdf version can be found here \sphinxhref{https://github.com/LorenzF/data-science-practical-approach/raw/main/src/\_build/latex/book.pdf}{here}.


\part{1. Introduction}


\chapter{Introduction}
\label{\detokenize{c1_introduction/introduction:introduction}}\label{\detokenize{c1_introduction/introduction::doc}}
\sphinxAtStartPar
this is an introduction


\part{2. Data Preparation}


\chapter{Data Preparation}
\label{\detokenize{c2_data_preparation/introduction:data-preparation}}\label{\detokenize{c2_data_preparation/introduction::doc}}
\sphinxAtStartPar
this is an introduction


\chapter{Indexing and slicing}
\label{\detokenize{c2_data_preparation/indexing_slicing:indexing-and-slicing}}\label{\detokenize{c2_data_preparation/indexing_slicing::doc}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{min\PYGZus{}temp\PYGZus{}df} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily\PYGZhy{}min\PYGZhy{}temperatures.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{min\PYGZus{}temp\PYGZus{}df}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
            Date  Temp
0     1981\PYGZhy{}01\PYGZhy{}01  20.7
1     1981\PYGZhy{}01\PYGZhy{}02  17.9
2     1981\PYGZhy{}01\PYGZhy{}03  18.8
3     1981\PYGZhy{}01\PYGZhy{}04  14.6
4     1981\PYGZhy{}01\PYGZhy{}05  15.8
...          ...   ...
3645  1990\PYGZhy{}12\PYGZhy{}27  14.0
3646  1990\PYGZhy{}12\PYGZhy{}28  13.6
3647  1990\PYGZhy{}12\PYGZhy{}29  13.5
3648  1990\PYGZhy{}12\PYGZhy{}30  15.7
3649  1990\PYGZhy{}12\PYGZhy{}31  13.0

[3650 rows x 2 columns]
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{min\PYGZus{}temp\PYGZus{}df}\PYG{o}{.}\PYG{n}{Date} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{to\PYGZus{}datetime}\PYG{p}{(}\PYG{n}{min\PYGZus{}temp\PYGZus{}df}\PYG{o}{.}\PYG{n}{Date}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{min\PYGZus{}temp\PYGZus{}df} \PYG{o}{=} \PYG{n}{min\PYGZus{}temp\PYGZus{}df}\PYG{o}{.}\PYG{n}{set\PYGZus{}index}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Date}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{min\PYGZus{}temp\PYGZus{}df}\PYG{o}{.}\PYG{n}{loc}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{1989\PYGZhy{}06\PYGZhy{}01}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{1989\PYGZhy{}06\PYGZhy{}30}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
            Temp
Date            
1989\PYGZhy{}06\PYGZhy{}01   2.3
1989\PYGZhy{}06\PYGZhy{}02   1.4
1989\PYGZhy{}06\PYGZhy{}03   2.1
1989\PYGZhy{}06\PYGZhy{}04   6.6
1989\PYGZhy{}06\PYGZhy{}05   8.9
1989\PYGZhy{}06\PYGZhy{}06   7.8
1989\PYGZhy{}06\PYGZhy{}07   9.0
1989\PYGZhy{}06\PYGZhy{}08  10.3
1989\PYGZhy{}06\PYGZhy{}09   7.9
1989\PYGZhy{}06\PYGZhy{}10   7.2
1989\PYGZhy{}06\PYGZhy{}11   8.6
1989\PYGZhy{}06\PYGZhy{}12   8.8
1989\PYGZhy{}06\PYGZhy{}13   6.2
1989\PYGZhy{}06\PYGZhy{}14   9.5
1989\PYGZhy{}06\PYGZhy{}15  10.2
1989\PYGZhy{}06\PYGZhy{}16   9.7
1989\PYGZhy{}06\PYGZhy{}17  11.2
1989\PYGZhy{}06\PYGZhy{}18  10.2
1989\PYGZhy{}06\PYGZhy{}19  10.1
1989\PYGZhy{}06\PYGZhy{}20   8.1
1989\PYGZhy{}06\PYGZhy{}21   6.6
1989\PYGZhy{}06\PYGZhy{}22   5.0
1989\PYGZhy{}06\PYGZhy{}23   4.7
1989\PYGZhy{}06\PYGZhy{}24   5.3
1989\PYGZhy{}06\PYGZhy{}25   4.5
1989\PYGZhy{}06\PYGZhy{}26   2.3
1989\PYGZhy{}06\PYGZhy{}27   1.4
1989\PYGZhy{}06\PYGZhy{}28   0.5
1989\PYGZhy{}06\PYGZhy{}29   2.4
1989\PYGZhy{}06\PYGZhy{}30   8.0
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{min\PYGZus{}temp\PYGZus{}df}\PYG{o}{.}\PYG{n}{loc}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{1989\PYGZhy{}06\PYGZhy{}01}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{1989\PYGZhy{}06\PYGZhy{}30}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Temp    6.56
dtype: float64
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{seaborn} \PYG{k}{as} \PYG{n+nn}{sns}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tip\PYGZus{}df} \PYG{o}{=} \PYG{n}{sns}\PYG{o}{.}\PYG{n}{load\PYGZus{}dataset}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{tips}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{tip\PYGZus{}df}\PYG{o}{.}\PYG{n}{head}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
   total\PYGZus{}bill   tip     sex smoker  day    time  size
0       16.99  1.01  Female     No  Sun  Dinner     2
1       10.34  1.66    Male     No  Sun  Dinner     3
2       21.01  3.50    Male     No  Sun  Dinner     3
3       23.68  3.31    Male     No  Sun  Dinner     2
4       24.59  3.61  Female     No  Sun  Dinner     4
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tip\PYGZus{}index\PYGZus{}df} \PYG{o}{=} \PYG{n}{tip\PYGZus{}df}\PYG{o}{.}\PYG{n}{set\PYGZus{}index}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{day}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tip\PYGZus{}index\PYGZus{}df}\PYG{o}{.}\PYG{n}{loc}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Sun}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
     total\PYGZus{}bill   tip     sex smoker    time  size
day                                               
Sun       16.99  1.01  Female     No  Dinner     2
Sun       10.34  1.66    Male     No  Dinner     3
Sun       21.01  3.50    Male     No  Dinner     3
Sun       23.68  3.31    Male     No  Dinner     2
Sun       24.59  3.61  Female     No  Dinner     4
..          ...   ...     ...    ...     ...   ...
Sun       20.90  3.50  Female    Yes  Dinner     3
Sun       30.46  2.00    Male    Yes  Dinner     5
Sun       18.15  3.50  Female    Yes  Dinner     3
Sun       23.10  4.00    Male    Yes  Dinner     3
Sun       15.69  1.50    Male    Yes  Dinner     2

[76 rows x 6 columns]
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tip\PYGZus{}index\PYGZus{}df} \PYG{o}{=} \PYG{n}{tip\PYGZus{}df}\PYG{o}{.}\PYG{n}{set\PYGZus{}index}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{day}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{time}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tip\PYGZus{}index\PYGZus{}df}\PYG{o}{.}\PYG{n}{loc}\PYG{p}{[}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Thur}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Lunch}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}\PYG{o}{.}\PYG{n}{tip}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
/tmp/ipykernel\PYGZus{}36874/2537502835.py:1: PerformanceWarning: indexing past lexsort depth may impact performance.
  tip\PYGZus{}index\PYGZus{}df.loc[(\PYGZsq{}Thur\PYGZsq{},\PYGZsq{}Lunch\PYGZsq{})].tip.mean()
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
2.767704918032786
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{pd}\PYG{o}{.}\PYG{n}{pivot\PYGZus{}table}\PYG{p}{(}\PYG{n}{tip\PYGZus{}df}\PYG{p}{,} \PYG{n}{values}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{total\PYGZus{}bill}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{index}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{day}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{columns}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{time}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{aggfunc}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{median}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
time  Lunch  Dinner
day                
Thur  16.00  18.780
Fri   13.42  18.665
Sat     NaN  18.240
Sun     NaN  19.630
\end{sphinxVerbatim}


\chapter{Missing Data}
\label{\detokenize{c2_data_preparation/missing_data:missing-data}}\label{\detokenize{c2_data_preparation/missing_data::doc}}
\sphinxAtStartPar
In this notebook we will look at a few datasets where values from columns are missing.
It is crucial for data science and machine learning to have a dataset where no values are missing as algorithms are usually not able to handle data with information missing.

\sphinxAtStartPar
For python, we will be using the pandas library to handle our dataset.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}
\end{sphinxVerbatim}


\section{Kamyr digester}
\label{\detokenize{c2_data_preparation/missing_data:kamyr-digester}}
\sphinxAtStartPar
The first dataset we will be looking at is taken from a psysical device equiped with numerous sensors, each timepoint (1 hour) these sensors are read out and the data is collected. Let’s have a look at the general structure

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{kamyr\PYGZus{}df} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://openmv.net/file/kamyr\PYGZhy{}digester.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{kamyr\PYGZus{}df}\PYG{o}{.}\PYG{n}{head}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
  Observation  Y\PYGZhy{}Kappa  ChipRate  BF\PYGZhy{}CMratio  BlowFlow  ChipLevel4   \PYGZbs{}
0    31\PYGZhy{}00:00    23.10    16.520     121.717  1177.607      169.805   
1    31\PYGZhy{}01:00    27.60    16.810      79.022  1328.360      341.327   
2    31\PYGZhy{}02:00    23.19    16.709      79.562  1329.407      239.161   
3    31\PYGZhy{}03:00    23.60    16.478      81.011  1334.877      213.527   
4    31\PYGZhy{}04:00    22.90    15.618      93.244  1334.168      243.131   

   T\PYGZhy{}upperExt\PYGZhy{}2   T\PYGZhy{}lowerExt\PYGZhy{}2    UCZAA  WhiteFlow\PYGZhy{}4   ...  SteamFlow\PYGZhy{}4   \PYGZbs{}
0        358.282         329.545  1.443       599.253  ...        67.122   
1        351.050         329.067  1.549       537.201  ...        60.012   
2        350.022         329.260  1.600       549.611  ...        61.304   
3        350.938         331.142  1.604       623.362  ...        68.496   
4        351.640         332.709    NaN       638.672  ...        70.022   

   Lower\PYGZhy{}HeatT\PYGZhy{}3  Upper\PYGZhy{}HeatT\PYGZhy{}3   ChipMass\PYGZhy{}4   WeakLiquorF   BlackFlow\PYGZhy{}2   \PYGZbs{}
0        329.432         303.099      175.964      1127.197      1319.039   
1        330.823         304.879      163.202       665.975      1297.317   
2        329.140         303.383      164.013       677.534      1327.072   
3        328.875         302.254      181.487       767.853      1324.461   
4        328.352         300.954      183.929       888.448      1343.424   

   WeakWashF   SteamHeatF\PYGZhy{}3   T\PYGZhy{}Top\PYGZhy{}Chips\PYGZhy{}4   SulphidityL\PYGZhy{}4   
0     257.325         54.612         252.077             NaN  
1     241.182         46.603         251.406           29.11  
2     237.272         51.795         251.335             NaN  
3     239.478         54.846         250.312           29.02  
4     215.372         54.186         249.916           29.01  

[5 rows x 23 columns]
\end{sphinxVerbatim}

\sphinxAtStartPar
Interesting, there seem to be 22 sensor values and 1 timestamp for each record. As mechanical devices are prone to noise and dropouts of sensors we would be foolish to assume no missing values are present.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{kamyr\PYGZus{}df}\PYG{o}{.}\PYG{n}{isna}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{divide}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{kamyr\PYGZus{}df}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{round}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{o}{*}\PYG{l+m+mi}{100}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Observation         0.00
Y\PYGZhy{}Kappa             0.00
ChipRate            1.33
BF\PYGZhy{}CMratio          4.65
BlowFlow            4.32
ChipLevel4          0.33
T\PYGZhy{}upperExt\PYGZhy{}2        0.33
T\PYGZhy{}lowerExt\PYGZhy{}2        0.33
UCZAA               7.97
WhiteFlow\PYGZhy{}4         0.33
AAWhiteSt\PYGZhy{}4        46.84
AA\PYGZhy{}Wood\PYGZhy{}4           0.33
ChipMoisture\PYGZhy{}4      0.33
SteamFlow\PYGZhy{}4         0.33
Lower\PYGZhy{}HeatT\PYGZhy{}3       0.33
Upper\PYGZhy{}HeatT\PYGZhy{}3       0.33
ChipMass\PYGZhy{}4          0.33
WeakLiquorF         0.33
BlackFlow\PYGZhy{}2         0.33
WeakWashF           0.33
SteamHeatF\PYGZhy{}3        0.33
T\PYGZhy{}Top\PYGZhy{}Chips\PYGZhy{}4       0.33
SulphidityL\PYGZhy{}4      46.84
dtype: float64
\end{sphinxVerbatim}

\sphinxAtStartPar
As expected, the datapoint ‘AAWhiteSt\sphinxhyphen{}4’ even has 46\% of data missing!
It seems we only have 300 datapoints and presumably these missing values occur in different records our dataset will be decimated if we just drop all rows with missing values.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{kamyr\PYGZus{}df}\PYG{o}{.}\PYG{n}{shape}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(301, 23)
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{kamyr\PYGZus{}df}\PYG{o}{.}\PYG{n}{dropna}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{shape}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(131, 23)
\end{sphinxVerbatim}

\sphinxAtStartPar
As we drop all rows with missing values, we are left with only 131 records.
Whilst this might be good enough for some purposes, there are more viable options.

\sphinxAtStartPar
Perhaps we can first remove the column with the most missing values and then drop all remaining

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{kamyr\PYGZus{}df}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{n}{columns}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AAWhiteSt\PYGZhy{}4 }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{SulphidityL\PYGZhy{}4 }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{o}{.}\PYG{n}{dropna}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{shape}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(263, 21)
\end{sphinxVerbatim}

\sphinxAtStartPar
Significantly better, although we lost the information of 2 sensors we now have a complete dataset with 263 records. For purposes where those 2 sensors are irrelevant this is a viable option, keep in mind that this dataset is still 100\% truthful, as we have not imputed any values.

\sphinxAtStartPar
Another option, where we retain all our records would be using the timely nature of our dataset, each record is a measurement with an interval of 1 hour. I have no knowledge of this dataset but one might make the assumption that the interval of 1 hour is taken as the state of the machine does not alter much in 1 hour. Therefore we could do what is called a forward fill, where we fill in the missing values with the same value of the sensor for the previous measurement.

\sphinxAtStartPar
This would solve nearly all nan values as there might be a problem where the first value is missing. This is shown below.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{kamyr\PYGZus{}df}\PYG{o}{.}\PYG{n}{fillna}\PYG{p}{(}\PYG{n}{method}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ffill}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{SulphidityL\PYGZhy{}4 }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
0        NaN
1      29.11
2      29.11
3      29.02
4      29.01
       ...  
296    30.43
297    30.29
298    30.47
299    30.47
300    30.46
Name: SulphidityL\PYGZhy{}4 , Length: 301, dtype: float64
\end{sphinxVerbatim}

\sphinxAtStartPar
Although our dataset is not fully the truth, we can see that little to no changes occur in the sensor and using a forward fill is arguably the most suitable option.


\section{Travel times}
\label{\detokenize{c2_data_preparation/missing_data:travel-times}}
\sphinxAtStartPar
Another dataset from the same source contains a collection of recorded travel times and specific information about the travel itself as e.g.: the day of the week, where they were going, …

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{travel\PYGZus{}df} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://openmv.net/file/travel\PYGZhy{}times.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{travel\PYGZus{}df}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
          Date StartTime  DayOfWeek GoingTo  Distance  MaxSpeed  AvgSpeed  \PYGZbs{}
0     1/6/2012     16:37     Friday    Home     51.29     127.4      78.3   
1     1/6/2012     08:20     Friday     GSK     51.63     130.3      81.8   
2     1/4/2012     16:17  Wednesday    Home     51.27     127.4      82.0   
3     1/4/2012     07:53  Wednesday     GSK     49.17     132.3      74.2   
4     1/3/2012     18:57    Tuesday    Home     51.15     136.2      83.4   
..         ...       ...        ...     ...       ...       ...       ...   
200  7/18/2011     08:09     Monday     GSK     54.52     125.6      49.9   
201  7/14/2011     08:03   Thursday     GSK     50.90     123.7      76.2   
202  7/13/2011     17:08  Wednesday    Home     51.96     132.6      57.5   
203  7/12/2011     17:51    Tuesday    Home     53.28     125.8      61.6   
204  7/11/2011     16:56     Monday    Home     51.73     125.0      62.8   

     AvgMovingSpeed FuelEconomy  TotalTime  MovingTime Take407All Comments  
0              84.8         NaN       39.3        36.3         No      NaN  
1              88.9         NaN       37.9        34.9         No      NaN  
2              85.8         NaN       37.5        35.9         No      NaN  
3              82.9         NaN       39.8        35.6         No      NaN  
4              88.1         NaN       36.8        34.8         No      NaN  
..              ...         ...        ...         ...        ...      ...  
200            82.4        7.89       65.5        39.7         No      NaN  
201            95.1        7.89       40.1        32.1        Yes      NaN  
202            76.7         NaN       54.2        40.6        Yes      NaN  
203            87.6         NaN       51.9        36.5        Yes      NaN  
204            92.5         NaN       49.5        33.6        Yes      NaN  

[205 rows x 13 columns]
\end{sphinxVerbatim}

\sphinxAtStartPar
we have a total of 205 records and we can already see that the FuelEconomy column seems pretty bad, let’s quantify that.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{travel\PYGZus{}df}\PYG{o}{.}\PYG{n}{isna}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{divide}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{travel\PYGZus{}df}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{round}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{o}{*}\PYG{l+m+mi}{100}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Date               0.00
StartTime          0.00
DayOfWeek          0.00
GoingTo            0.00
Distance           0.00
MaxSpeed           0.00
AvgSpeed           0.00
AvgMovingSpeed     0.00
FuelEconomy        8.29
TotalTime          0.00
MovingTime         0.00
Take407All         0.00
Comments          88.29
dtype: float64
\end{sphinxVerbatim}

\sphinxAtStartPar
In the end, it doesn’t seem that bad, but there are comments and nearly none of them are filled in. Which in perspective is understandable. Let’s see what the comments look like

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{travel\PYGZus{}df}\PYG{p}{[}\PYG{o}{\PYGZti{}}\PYG{n}{travel\PYGZus{}df}\PYG{o}{.}\PYG{n}{Comments}\PYG{o}{.}\PYG{n}{isna}\PYG{p}{(}\PYG{p}{)}\PYG{p}{]}\PYG{o}{.}\PYG{n}{Comments}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
15                                  Put snow tires on
39                                         Heavy rain
49                                Huge traffic backup
50      Pumped tires up: check fuel economy improved?
52                                Backed up at Bronte
54                                Backed up at Bronte
60                                              Rainy
78                                   Rain, rain, rain
91                                   Rain, rain, rain
92         Accident: backup from Hamilton to 407 ramp
110                                           Raining
132                           Back to school traffic?
133                Took 407 all the way (to McMaster)
150                             Heavy volume on Derry
156                        Start early to run a batch
158    Accident at 403/highway 6; detour along Dundas
165                                      Detour taken
166                                    Must be Friday
172                             Medium amount of rain
174                                         New tires
182                              Turn around on Derry
184                                       Empty roads
187                            Police slowdown on 403
189                         Accident blocked 407 exit
Name: Comments, dtype: object
\end{sphinxVerbatim}

\sphinxAtStartPar
As you would expect, these comments are text based. Now imagine we would like to run some Natural Language Processing (NLP) on these, it would be a pain to perform string operations on it when it is riddled with missing values.

\sphinxAtStartPar
Here a simple example where we select all records containing the word ‘rain’, with no avail.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{travel\PYGZus{}df}\PYG{p}{[}\PYG{n}{travel\PYGZus{}df}\PYG{o}{.}\PYG{n}{Comments}\PYG{o}{.}\PYG{n}{str}\PYG{o}{.}\PYG{n}{lower}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{str}\PYG{o}{.}\PYG{n}{contains}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{rain}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gt}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{n+ne}{ValueError}\PYG{g+gWhitespace}{                                }Traceback (most recent call last)
\PYG{o}{/}\PYG{n}{tmp}\PYG{o}{/}\PYG{n}{ipykernel\PYGZus{}36906}\PYG{o}{/}\PYG{l+m+mf}{1298831137.}\PYG{n}{py} \PYG{o+ow}{in} \PYG{o}{\PYGZlt{}}\PYG{n}{module}\PYG{o}{\PYGZgt{}}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{1} \PYG{n}{travel\PYGZus{}df}\PYG{p}{[}\PYG{n}{travel\PYGZus{}df}\PYG{o}{.}\PYG{n}{Comments}\PYG{o}{.}\PYG{n}{str}\PYG{o}{.}\PYG{n}{lower}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{str}\PYG{o}{.}\PYG{n}{contains}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{rain}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}

\PYG{n+nn}{\PYGZti{}/git/data\PYGZhy{}science\PYGZhy{}practical\PYGZhy{}approach/venv/lib/python3.8/site\PYGZhy{}packages/pandas/core/frame.py} in \PYG{n+ni}{\PYGZus{}\PYGZus{}getitem\PYGZus{}\PYGZus{}}\PYG{n+nt}{(self, key)}
\PYG{g+gWhitespace}{   }\PYG{l+m+mi}{3446} 
\PYG{g+gWhitespace}{   }\PYG{l+m+mi}{3447}         \PYG{c+c1}{\PYGZsh{} Do we have a (boolean) 1d indexer?}
\PYG{n+ne}{\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{3448}         \PYG{k}{if} \PYG{n}{com}\PYG{o}{.}\PYG{n}{is\PYGZus{}bool\PYGZus{}indexer}\PYG{p}{(}\PYG{n}{key}\PYG{p}{)}\PYG{p}{:}
\PYG{g+gWhitespace}{   }\PYG{l+m+mi}{3449}             \PYG{k}{return} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{\PYGZus{}getitem\PYGZus{}bool\PYGZus{}array}\PYG{p}{(}\PYG{n}{key}\PYG{p}{)}
\PYG{g+gWhitespace}{   }\PYG{l+m+mi}{3450} 

\PYG{n+nn}{\PYGZti{}/git/data\PYGZhy{}science\PYGZhy{}practical\PYGZhy{}approach/venv/lib/python3.8/site\PYGZhy{}packages/pandas/core/common.py} in \PYG{n+ni}{is\PYGZus{}bool\PYGZus{}indexer}\PYG{n+nt}{(key)}
\PYG{g+gWhitespace}{    }\PYG{l+m+mi}{137}                     \PYG{c+c1}{\PYGZsh{} Don\PYGZsq{}t raise on e.g. [\PYGZdq{}A\PYGZdq{}, \PYGZdq{}B\PYGZdq{}, np.nan], see}
\PYG{g+gWhitespace}{    }\PYG{l+m+mi}{138}                     \PYG{c+c1}{\PYGZsh{}  test\PYGZus{}loc\PYGZus{}getitem\PYGZus{}list\PYGZus{}of\PYGZus{}labels\PYGZus{}categoricalindex\PYGZus{}with\PYGZus{}na}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{139}                     \PYG{k}{raise} \PYG{n+ne}{ValueError}\PYG{p}{(}\PYG{n}{na\PYGZus{}msg}\PYG{p}{)}
\PYG{g+gWhitespace}{    }\PYG{l+m+mi}{140}                 \PYG{k}{return} \PYG{k+kc}{False}
\PYG{g+gWhitespace}{    }\PYG{l+m+mi}{141}             \PYG{k}{return} \PYG{k+kc}{True}

\PYG{n+ne}{ValueError}: Cannot mask with non\PYGZhy{}boolean array containing NA / NaN values
\end{sphinxVerbatim}

\sphinxAtStartPar
The last line of the python error traceback gives us the reason it failed, because there were NaN values present.

\sphinxAtStartPar
Luckily the string variable has more or less it’s on ‘null’ value, being an empty string, this way these operations are still possible, most of the comments will just contain nothing.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{travel\PYGZus{}df}\PYG{o}{.}\PYG{n}{Comments} \PYG{o}{=} \PYG{n}{travel\PYGZus{}df}\PYG{o}{.}\PYG{n}{Comments}\PYG{o}{.}\PYG{n}{fillna}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{travel\PYGZus{}df}\PYG{p}{[}\PYG{n}{travel\PYGZus{}df}\PYG{o}{.}\PYG{n}{Comments}\PYG{o}{.}\PYG{n}{str}\PYG{o}{.}\PYG{n}{lower}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{str}\PYG{o}{.}\PYG{n}{contains}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{rain}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
           Date StartTime  DayOfWeek GoingTo  Distance  MaxSpeed  AvgSpeed  \PYGZbs{}
39   11/29/2011     07:23    Tuesday     GSK     51.74     112.2      55.3   
60    11/9/2011     16:15  Wednesday    Home     51.28     121.4      65.9   
78   10/25/2011     17:24    Tuesday    Home     52.87     123.5      65.1   
91   10/12/2011     17:47  Wednesday    Home     51.40     114.4      59.7   
110   9/27/2011     07:36    Tuesday     GSK     50.65     128.1      86.3   
172    8/9/2011     08:15    Tuesday     GSK     49.08     134.8      60.5   

     AvgMovingSpeed FuelEconomy  TotalTime  MovingTime Take407All  \PYGZbs{}
39             61.0         NaN       56.2        50.9         No   
60             71.8        9.35       46.7        42.1         No   
78             72.4        8.97       48.7        43.8         No   
91             65.8        8.75       51.7        46.9         No   
110            88.6        8.31       35.2        34.3        Yes   
172            67.2        8.54       48.7        43.8         No   

                  Comments  
39              Heavy rain  
60                   Rainy  
78        Rain, rain, rain  
91        Rain, rain, rain  
110                Raining  
172  Medium amount of rain  
\end{sphinxVerbatim}

\sphinxAtStartPar
Fixed! now we can use the comments for analysis.

\sphinxAtStartPar
We still have to fix the FuelEconomy, let us take a look at the non NaN values

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{travel\PYGZus{}df}\PYG{p}{[}\PYG{o}{\PYGZti{}}\PYG{n}{travel\PYGZus{}df}\PYG{o}{.}\PYG{n}{FuelEconomy}\PYG{o}{.}\PYG{n}{isna}\PYG{p}{(}\PYG{p}{)}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
           Date StartTime  DayOfWeek GoingTo  Distance  MaxSpeed  AvgSpeed  \PYGZbs{}
6      1/2/2012     17:31     Monday    Home     51.37     123.2      82.9   
7      1/2/2012     07:34     Monday     GSK     49.01     128.3      77.5   
8    12/23/2011     08:01     Friday     GSK     52.91     130.3      80.9   
9    12/22/2011     17:19   Thursday    Home     51.17     122.3      70.6   
10   12/22/2011     08:16   Thursday     GSK     49.15     129.4      74.0   
..          ...       ...        ...     ...       ...       ...       ...   
197   7/20/2011     08:24  Wednesday     GSK     48.50     125.8      75.7   
198   7/19/2011     17:17    Tuesday    Home     51.16     126.7      92.2   
199   7/19/2011     08:11    Tuesday     GSK     50.96     124.3      82.3   
200   7/18/2011     08:09     Monday     GSK     54.52     125.6      49.9   
201   7/14/2011     08:03   Thursday     GSK     50.90     123.7      76.2   

     AvgMovingSpeed FuelEconomy  TotalTime  MovingTime Take407All Comments  
6              87.3           \PYGZhy{}       37.2        35.3         No           
7              85.9           \PYGZhy{}       37.9        34.3         No           
8              88.3        8.89       39.3        36.0         No           
9              78.1        8.89       43.5        39.3         No           
10             81.4        8.89       39.8        36.2         No           
..              ...         ...        ...         ...        ...      ...  
197            87.3        7.89       38.5        33.3        Yes           
198           102.6        7.89       33.3        29.9        Yes           
199            96.4        7.89       37.2        31.7        Yes           
200            82.4        7.89       65.5        39.7         No           
201            95.1        7.89       40.1        32.1        Yes           

[188 rows x 13 columns]
\end{sphinxVerbatim}

\sphinxAtStartPar
It seems that aside NaN values there are also other intruders, a quick check on the data type (Dtype) reveils it is not recognised as a number!

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{travel\PYGZus{}df}\PYG{o}{.}\PYG{n}{info}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}class \PYGZsq{}pandas.core.frame.DataFrame\PYGZsq{}\PYGZgt{}
RangeIndex: 205 entries, 0 to 204
Data columns (total 13 columns):
 \PYGZsh{}   Column          Non\PYGZhy{}Null Count  Dtype  
\PYGZhy{}\PYGZhy{}\PYGZhy{}  \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}          \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}  \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}  
 0   Date            205 non\PYGZhy{}null    object 
 1   StartTime       205 non\PYGZhy{}null    object 
 2   DayOfWeek       205 non\PYGZhy{}null    object 
 3   GoingTo         205 non\PYGZhy{}null    object 
 4   Distance        205 non\PYGZhy{}null    float64
 5   MaxSpeed        205 non\PYGZhy{}null    float64
 6   AvgSpeed        205 non\PYGZhy{}null    float64
 7   AvgMovingSpeed  205 non\PYGZhy{}null    float64
 8   FuelEconomy     188 non\PYGZhy{}null    object 
 9   TotalTime       205 non\PYGZhy{}null    float64
 10  MovingTime      205 non\PYGZhy{}null    float64
 11  Take407All      205 non\PYGZhy{}null    object 
 12  Comments        205 non\PYGZhy{}null    object 
dtypes: float64(6), object(7)
memory usage: 20.9+ KB
\end{sphinxVerbatim}

\sphinxAtStartPar
The column is noted as an object or string type, meaning that these numbers are given as ‘9.24’ instead of 9.24 and numerical operations are not possible.
We can cast them to numeric but have to warn pandas to coerce errors, meaning errors will be converted to NaN values.
Later we’ll handle the NaN’s.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{travel\PYGZus{}df}\PYG{o}{.}\PYG{n}{FuelEconomy} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{to\PYGZus{}numeric}\PYG{p}{(}\PYG{n}{travel\PYGZus{}df}\PYG{o}{.}\PYG{n}{FuelEconomy}\PYG{p}{,} \PYG{n}{errors}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{coerce}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{travel\PYGZus{}df}\PYG{o}{.}\PYG{n}{info}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}class \PYGZsq{}pandas.core.frame.DataFrame\PYGZsq{}\PYGZgt{}
RangeIndex: 205 entries, 0 to 204
Data columns (total 13 columns):
 \PYGZsh{}   Column          Non\PYGZhy{}Null Count  Dtype  
\PYGZhy{}\PYGZhy{}\PYGZhy{}  \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}          \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}  \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}  
 0   Date            205 non\PYGZhy{}null    object 
 1   StartTime       205 non\PYGZhy{}null    object 
 2   DayOfWeek       205 non\PYGZhy{}null    object 
 3   GoingTo         205 non\PYGZhy{}null    object 
 4   Distance        205 non\PYGZhy{}null    float64
 5   MaxSpeed        205 non\PYGZhy{}null    float64
 6   AvgSpeed        205 non\PYGZhy{}null    float64
 7   AvgMovingSpeed  205 non\PYGZhy{}null    float64
 8   FuelEconomy     186 non\PYGZhy{}null    float64
 9   TotalTime       205 non\PYGZhy{}null    float64
 10  MovingTime      205 non\PYGZhy{}null    float64
 11  Take407All      205 non\PYGZhy{}null    object 
 12  Comments        205 non\PYGZhy{}null    object 
dtypes: float64(7), object(6)
memory usage: 20.9+ KB
\end{sphinxVerbatim}

\sphinxAtStartPar
Wonderful, now the column is numerical and we can see 2 more missing values have popped up!
We could easily drop these 19 records and have a complete dataset.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{travel\PYGZus{}df}\PYG{o}{.}\PYG{n}{dropna}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
           Date StartTime  DayOfWeek GoingTo  Distance  MaxSpeed  AvgSpeed  \PYGZbs{}
8    12/23/2011     08:01     Friday     GSK     52.91     130.3      80.9   
9    12/22/2011     17:19   Thursday    Home     51.17     122.3      70.6   
10   12/22/2011     08:16   Thursday     GSK     49.15     129.4      74.0   
11   12/21/2011     07:45  Wednesday     GSK     51.77     124.8      71.7   
12   12/20/2011     16:05    Tuesday    Home     51.45     130.1      75.2   
..          ...       ...        ...     ...       ...       ...       ...   
197   7/20/2011     08:24  Wednesday     GSK     48.50     125.8      75.7   
198   7/19/2011     17:17    Tuesday    Home     51.16     126.7      92.2   
199   7/19/2011     08:11    Tuesday     GSK     50.96     124.3      82.3   
200   7/18/2011     08:09     Monday     GSK     54.52     125.6      49.9   
201   7/14/2011     08:03   Thursday     GSK     50.90     123.7      76.2   

     AvgMovingSpeed  FuelEconomy  TotalTime  MovingTime Take407All Comments  
8              88.3         8.89       39.3        36.0         No           
9              78.1         8.89       43.5        39.3         No           
10             81.4         8.89       39.8        36.2         No           
11             78.9         8.89       43.3        39.4         No           
12             82.7         8.89       41.1        37.3         No           
..              ...          ...        ...         ...        ...      ...  
197            87.3         7.89       38.5        33.3        Yes           
198           102.6         7.89       33.3        29.9        Yes           
199            96.4         7.89       37.2        31.7        Yes           
200            82.4         7.89       65.5        39.7         No           
201            95.1         7.89       40.1        32.1        Yes           

[186 rows x 13 columns]
\end{sphinxVerbatim}

\sphinxAtStartPar
However im leaving them as an excercise for you to apply a technique we will see in the next part


\section{Material properties}
\label{\detokenize{c2_data_preparation/missing_data:material-properties}}
\sphinxAtStartPar
Another dataset from the same source contains the material properties from 30 samples, this time there is not timestamp as the samples are not related in time with each other.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{material\PYGZus{}df} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{http://openmv.net/file/raw\PYGZhy{}material\PYGZhy{}properties.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{material\PYGZus{}df}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
    Sample  size1  size2  size3  density1  density2  density3
0   X12558  0.696   2.69   6.38      41.8     17.18      3.90
1   X14728  0.636   2.30   5.14      38.1     12.73      3.89
2   X15468  0.841   2.85   5.20      37.6     13.58      3.98
3   X21364  0.609   2.13   4.62      34.2     11.12      4.02
4   X23671  0.684   2.16   4.87      36.4     12.24      3.92
5   X24055  0.762   2.81   6.36      38.1     13.28      3.89
6   X24905  0.552   2.34   5.03      41.3     16.71      3.86
7   X25917  0.501   2.17   5.09       NaN       NaN       NaN
8   X27871  0.619   2.11   5.13       NaN       NaN       NaN
9   X28690  0.610   2.10   4.18      35.0     12.15      3.86
10  X31385  0.532   2.09   4.93       NaN       NaN       NaN
11  X31813  0.738   2.29   5.47       NaN       NaN       NaN
12  X32807  0.779   2.62   5.59       NaN       NaN       NaN
13  X33943  0.537   2.23   5.41      35.2     11.34      3.99
14  X35035  0.702   2.05   5.10      34.2     10.54      4.02
15  X39223  0.768   2.51   5.09      34.9     12.55      3.90
16  X40503  0.714   2.56   6.03      35.6     12.20      4.02
17  X41400  0.621   2.42   5.10      38.7     14.27      3.98
18  X42988  0.726   2.11   4.69      37.1     13.14      3.98
19  X44749  0.698   2.36   5.40      36.6     12.16      4.01
20  X45295    NaN    NaN    NaN      38.1     13.34      3.89
21  X46965  0.759   2.47   4.83      38.7     14.83      3.89
22  X49666  0.535   2.13   5.23       NaN       NaN       NaN
23  X50678  0.716   2.29   5.45      37.3     13.70      3.92
24  X52894  0.635   2.08   4.94       NaN       NaN       NaN
25  X53925  0.598   2.12   4.69      37.9     13.45      3.78
26  X54254  0.700   2.47   5.22      38.8     14.72      3.92
27  X54272  0.957   2.96   7.37      36.2     13.38      4.20
28  X54394  0.759   2.66   5.36      35.2     12.19      3.98
29  X55408  0.661   2.10   4.27       NaN       NaN       NaN
30  X56952  0.646   2.38   4.51      40.1     15.68      3.86
31  X57095  0.662   2.34   4.71      35.0     12.37      3.90
32  X57128  0.749   2.43   5.16      37.3     13.04      3.92
33  X61870  0.598   2.21   4.90       NaN       NaN       NaN
34  X61888  0.619   2.59   5.81       NaN       NaN       NaN
35  X72736  0.693   2.05   5.02      39.6     15.55      3.94
\end{sphinxVerbatim}

\sphinxAtStartPar
let us quantify the amount of missing data

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{material\PYGZus{}df}\PYG{o}{.}\PYG{n}{isna}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{divide}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{material\PYGZus{}df}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{round}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{o}{*}\PYG{l+m+mi}{100}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Sample       0.00
size1        2.78
size2        2.78
size3        2.78
density1    27.78
density2    27.78
density3    27.78
dtype: float64
\end{sphinxVerbatim}

\sphinxAtStartPar
Unfortunately that is a lot of missing data, covered in all records, dropping here seems almost impossible if we want to keep a healthy amount of records.

\sphinxAtStartPar
Here it would be wise to go for a more elaborate method of imputation, I opted for the K\sphinxhyphen{}nearest neighbours method, which looks at the K most similar records in the dataset to make an educated guess on what the missing value could be, this because we can assume that records with similar data are also similar over all the properties (columns).

\sphinxAtStartPar
Im using the sklearn library for this, which has more imputation techniques such as MICE.
More info can be found \sphinxhref{https://scikit-learn.org/stable/modules/impute.html}{here}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{impute} \PYG{k+kn}{import} \PYG{n}{KNNImputer}
\end{sphinxVerbatim}

\sphinxAtStartPar
im creating an imputer object and specify that i want to use the 5 most similar records and weigh them by distance from the to imputed record, meaning closer neighbours are more important.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{imputer} \PYG{o}{=} \PYG{n}{KNNImputer}\PYG{p}{(}\PYG{n}{n\PYGZus{}neighbors}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{weights}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{distance}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
As the imputer only takes numerical values I had to do some pandas magic and drop the first column, which I then added again. The result is a fully filled dataset, you can recognise the new values as they are not rounded.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{pd}\PYG{o}{.}\PYG{n}{DataFrame}\PYG{p}{(}
    \PYG{n}{imputer}\PYG{o}{.}\PYG{n}{fit\PYGZus{}transform}\PYG{p}{(}\PYG{n}{material\PYGZus{}df}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{n}{columns}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Sample}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} 
    \PYG{n}{columns}\PYG{o}{=}\PYG{n}{material\PYGZus{}df}\PYG{o}{.}\PYG{n}{columns}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Sample}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
       size1     size2     size3   density1   density2  density3
0   0.696000  2.690000  6.380000  41.800000  17.180000  3.900000
1   0.636000  2.300000  5.140000  38.100000  12.730000  3.890000
2   0.841000  2.850000  5.200000  37.600000  13.580000  3.980000
3   0.609000  2.130000  4.620000  34.200000  11.120000  4.020000
4   0.684000  2.160000  4.870000  36.400000  12.240000  3.920000
5   0.762000  2.810000  6.360000  38.100000  13.280000  3.890000
6   0.552000  2.340000  5.030000  41.300000  16.710000  3.860000
7   0.501000  2.170000  5.090000  38.495282  14.029399  3.931180
8   0.619000  2.110000  5.130000  37.405275  13.157346  3.943667
9   0.610000  2.100000  4.180000  35.000000  12.150000  3.860000
10  0.532000  2.090000  4.930000  37.811132  13.646072  3.908364
11  0.738000  2.290000  5.470000  37.088833  13.255412  3.941654
12  0.779000  2.620000  5.590000  36.540567  12.889902  3.970973
13  0.537000  2.230000  5.410000  35.200000  11.340000  3.990000
14  0.702000  2.050000  5.100000  34.200000  10.540000  4.020000
15  0.768000  2.510000  5.090000  34.900000  12.550000  3.900000
16  0.714000  2.560000  6.030000  35.600000  12.200000  4.020000
17  0.621000  2.420000  5.100000  38.700000  14.270000  3.980000
18  0.726000  2.110000  4.690000  37.100000  13.140000  3.980000
19  0.698000  2.360000  5.400000  36.600000  12.160000  4.010000
20  0.733097  2.653959  5.881504  38.100000  13.340000  3.890000
21  0.759000  2.470000  4.830000  38.700000  14.830000  3.890000
22  0.535000  2.130000  5.230000  37.391815  13.089536  3.944335
23  0.716000  2.290000  5.450000  37.300000  13.700000  3.920000
24  0.635000  2.080000  4.940000  37.254724  13.206262  3.933904
25  0.598000  2.120000  4.690000  37.900000  13.450000  3.780000
26  0.700000  2.470000  5.220000  38.800000  14.720000  3.920000
27  0.957000  2.960000  7.370000  36.200000  13.380000  4.200000
28  0.759000  2.660000  5.360000  35.200000  12.190000  3.980000
29  0.661000  2.100000  4.270000  36.172345  12.755632  3.887375
30  0.646000  2.380000  4.510000  40.100000  15.680000  3.860000
31  0.662000  2.340000  4.710000  35.000000  12.370000  3.900000
32  0.749000  2.430000  5.160000  37.300000  13.040000  3.920000
33  0.598000  2.210000  4.900000  37.865882  13.826029  3.887021
34  0.619000  2.590000  5.810000  35.932339  12.318210  3.989911
35  0.693000  2.050000  5.020000  39.600000  15.550000  3.940000
\end{sphinxVerbatim}

\sphinxAtStartPar
This concludes the part of missing values, perhaps you can try yourself and impute the missing values for the FuelEconomy using the SimpleImputer or even the IterativeImputer.


\chapter{Concatenation and deduplication}
\label{\detokenize{c2_data_preparation/concatenation_deduplication:concatenation-and-deduplication}}\label{\detokenize{c2_data_preparation/concatenation_deduplication::doc}}
\sphinxAtStartPar
\sphinxurl{https://s3.amazonaws.com/nyc-tlc/trip+data/yellow\_tripdata\_2020-01.csv}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gt}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{n+ne}{ModuleNotFoundError}\PYG{g+gWhitespace}{                       }Traceback (most recent call last)
\PYG{o}{/}\PYG{n}{tmp}\PYG{o}{/}\PYG{n}{ipykernel\PYGZus{}13304}\PYG{o}{/}\PYG{l+m+mf}{4080736814.}\PYG{n}{py} \PYG{o+ow}{in} \PYG{o}{\PYGZlt{}}\PYG{n}{module}\PYG{o}{\PYGZgt{}}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{1} \PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}

\PYG{n+ne}{ModuleNotFoundError}: No module named \PYGZsq{}pandas\PYGZsq{}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{df} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://s3.amazonaws.com/nyc\PYGZhy{}tlc/trip+data/yellow\PYGZus{}tripdata\PYGZus{}2020\PYGZhy{}01.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
/home/lorenzf/.local/lib/python3.8/site\PYGZhy{}packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low\PYGZus{}memory=False.
  exec(code\PYGZus{}obj, self.user\PYGZus{}global\PYGZus{}ns, self.user\PYGZus{}ns)
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{df}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
         VendorID tpep\PYGZus{}pickup\PYGZus{}datetime tpep\PYGZus{}dropoff\PYGZus{}datetime  passenger\PYGZus{}count  \PYGZbs{}
0             1.0  2020\PYGZhy{}01\PYGZhy{}01 00:28:15   2020\PYGZhy{}01\PYGZhy{}01 00:33:03              1.0   
1             1.0  2020\PYGZhy{}01\PYGZhy{}01 00:35:39   2020\PYGZhy{}01\PYGZhy{}01 00:43:04              1.0   
2             1.0  2020\PYGZhy{}01\PYGZhy{}01 00:47:41   2020\PYGZhy{}01\PYGZhy{}01 00:53:52              1.0   
3             1.0  2020\PYGZhy{}01\PYGZhy{}01 00:55:23   2020\PYGZhy{}01\PYGZhy{}01 01:00:14              1.0   
4             2.0  2020\PYGZhy{}01\PYGZhy{}01 00:01:58   2020\PYGZhy{}01\PYGZhy{}01 00:04:16              1.0   
...           ...                  ...                   ...              ...   
6405003       NaN  2020\PYGZhy{}01\PYGZhy{}31 22:51:00   2020\PYGZhy{}01\PYGZhy{}31 23:22:00              NaN   
6405004       NaN  2020\PYGZhy{}01\PYGZhy{}31 22:10:00   2020\PYGZhy{}01\PYGZhy{}31 23:26:00              NaN   
6405005       NaN  2020\PYGZhy{}01\PYGZhy{}31 22:50:07   2020\PYGZhy{}01\PYGZhy{}31 23:17:57              NaN   
6405006       NaN  2020\PYGZhy{}01\PYGZhy{}31 22:25:53   2020\PYGZhy{}01\PYGZhy{}31 22:48:32              NaN   
6405007       NaN  2020\PYGZhy{}01\PYGZhy{}31 22:44:00   2020\PYGZhy{}01\PYGZhy{}31 23:06:00              NaN   

         trip\PYGZus{}distance  RatecodeID store\PYGZus{}and\PYGZus{}fwd\PYGZus{}flag  PULocationID  \PYGZbs{}
0                 1.20         1.0                  N           238   
1                 1.20         1.0                  N           239   
2                 0.60         1.0                  N           238   
3                 0.80         1.0                  N           238   
4                 0.00         1.0                  N           193   
...                ...         ...                ...           ...   
6405003           3.24         NaN                NaN           237   
6405004          22.13         NaN                NaN           259   
6405005          10.51         NaN                NaN           137   
6405006           5.49         NaN                NaN            50   
6405007          11.60         NaN                NaN           179   

         DOLocationID  payment\PYGZus{}type  fare\PYGZus{}amount  extra  mta\PYGZus{}tax  tip\PYGZus{}amount  \PYGZbs{}
0                 239           1.0         6.00   3.00      0.5        1.47   
1                 238           1.0         7.00   3.00      0.5        1.50   
2                 238           1.0         6.00   3.00      0.5        1.00   
3                 151           1.0         5.50   0.50      0.5        1.36   
4                 193           2.0         3.50   0.50      0.5        0.00   
...               ...           ...          ...    ...      ...         ...   
6405003           234           NaN        17.59   2.75      0.5        0.00   
6405004            45           NaN        46.67   2.75      0.5        0.00   
6405005           169           NaN        48.85   2.75      0.0        0.00   
6405006            42           NaN        27.17   2.75      0.0        0.00   
6405007           205           NaN        54.56   2.75      0.5        0.00   

         tolls\PYGZus{}amount  improvement\PYGZus{}surcharge  total\PYGZus{}amount  \PYGZbs{}
0                0.00                    0.3         11.27   
1                0.00                    0.3         12.30   
2                0.00                    0.3         10.80   
3                0.00                    0.3          8.16   
4                0.00                    0.3          4.80   
...               ...                    ...           ...   
6405003          0.00                    0.3         21.14   
6405004         12.24                    0.3         62.46   
6405005          0.00                    0.3         51.90   
6405006          0.00                    0.3         30.22   
6405007          0.00                    0.3         58.11   

         congestion\PYGZus{}surcharge  
0                         2.5  
1                         2.5  
2                         2.5  
3                         0.0  
4                         0.0  
...                       ...  
6405003                   0.0  
6405004                   0.0  
6405005                   0.0  
6405006                   0.0  
6405007                   0.0  

[6405008 rows x 18 columns]
\end{sphinxVerbatim}


\chapter{Some practice}
\label{\detokenize{c2_data_preparation/some_practice:some-practice}}\label{\detokenize{c2_data_preparation/some_practice::doc}}
\sphinxAtStartPar
Now that you have learned techniques in data preparation, why don’t you put them to use in this wonderfully horrifying dataset. Good luck!

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{os}
\PYG{k+kn}{import} \PYG{n+nn}{json}

\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}
\PYG{k+kn}{import} \PYG{n+nn}{kaggle}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gt}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{n+ne}{ModuleNotFoundError}\PYG{g+gWhitespace}{                       }Traceback (most recent call last)
\PYG{o}{/}\PYG{n}{tmp}\PYG{o}{/}\PYG{n}{ipykernel\PYGZus{}36949}\PYG{o}{/}\PYG{l+m+mf}{2054829274.}\PYG{n}{py} \PYG{o+ow}{in} \PYG{o}{\PYGZlt{}}\PYG{n}{module}\PYG{o}{\PYGZgt{}}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{3} 
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{4} \PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{5} \PYG{k+kn}{import} \PYG{n+nn}{kaggle}

\PYG{n+ne}{ModuleNotFoundError}: No module named \PYGZsq{}kaggle\PYGZsq{}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{if} \PYG{o+ow}{not} \PYG{n}{os}\PYG{o}{.}\PYG{n}{path}\PYG{o}{.}\PYG{n}{exists}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/root/.kaggle}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{os}\PYG{o}{.}\PYG{n}{mkdir}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/root/.kaggle}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{k}{with} \PYG{n+nb}{open}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{/root/.kaggle/kaggle.json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{w}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} \PYG{k}{as} \PYG{n}{f}\PYG{p}{:}
    \PYG{n}{json}\PYG{o}{.}\PYG{n}{dump}\PYG{p}{(}
        \PYG{p}{\PYGZob{}}
            \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{username}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lorenzf}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
            \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{key}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{7a44a9e99b27e796177d793a3d85b8cf}\PYG{l+s+s2}{\PYGZdq{}}
        \PYG{p}{\PYGZcb{}}
        \PYG{p}{,} \PYG{n}{f}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{kaggle}\PYG{o}{.}\PYG{n}{api}\PYG{o}{.}\PYG{n}{dataset\PYGZus{}download\PYGZus{}files}\PYG{p}{(}\PYG{n}{dataset}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{PromptCloudHQ/us\PYGZhy{}jobs\PYGZhy{}on\PYGZhy{}monstercom}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{path}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{./data}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{unzip}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{df} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{./data/monster\PYGZus{}com\PYGZhy{}job\PYGZus{}sample.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{df}\PYG{o}{.}\PYG{n}{head}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
                    country country\PYGZus{}code date\PYGZus{}added has\PYGZus{}expired  \PYGZbs{}
0  United States of America           US        NaN          No   
1  United States of America           US        NaN          No   
2  United States of America           US        NaN          No   
3  United States of America           US        NaN          No   
4  United States of America           US        NaN          No   

          job\PYGZus{}board                                    job\PYGZus{}description  \PYGZbs{}
0  jobs.monster.com  TeamSoft is seeing an IT Support Specialist to...   
1  jobs.monster.com  The Wisconsin State Journal is seeking a flexi...   
2  jobs.monster.com  Report this job About the Job DePuy Synthes Co...   
3  jobs.monster.com  Why Join Altec? If you’re considering a career...   
4  jobs.monster.com  Position ID\PYGZsh{}  76162 \PYGZsh{} Positions  1 State  CT C...   

                                           job\PYGZus{}title             job\PYGZus{}type  \PYGZbs{}
0               IT Support Technician Job in Madison   Full Time Employee   
1            Business Reporter/Editor Job in Madison            Full Time   
2  Johnson \PYGZam{} Johnson Family of Companies Job Appl...  Full Time, Employee   
3                    Engineer \PYGZhy{} Quality Job in Dixon            Full Time   
4       Shift Supervisor \PYGZhy{} Part\PYGZhy{}Time Job in Camphill   Full Time Employee   

                                            location  \PYGZbs{}
0                                  Madison, WI 53702   
1                                  Madison, WI 53708   
2  DePuy Synthes Companies is a member of Johnson...   
3                                          Dixon, CA   
4                                       Camphill, PA   

                      organization  \PYGZbs{}
0                              NaN   
1          Printing and Publishing   
2  Personal and Household Services   
3                 Altec Industries   
4                           Retail   

                                            page\PYGZus{}url salary  \PYGZbs{}
0  http://jobview.monster.com/it\PYGZhy{}support\PYGZhy{}technici...    NaN   
1  http://jobview.monster.com/business\PYGZhy{}reporter\PYGZhy{}e...    NaN   
2  http://jobview.monster.com/senior\PYGZhy{}training\PYGZhy{}lea...    NaN   
3  http://jobview.monster.com/engineer\PYGZhy{}quality\PYGZhy{}jo...    NaN   
4  http://jobview.monster.com/shift\PYGZhy{}supervisor\PYGZhy{}pa...    NaN   

                       sector                           uniq\PYGZus{}id  
0     IT/Software Development  11d599f229a80023d2f40e7c52cd941e  
1                         NaN  e4cbb126dabf22159aff90223243ff2a  
2                         NaN  839106b353877fa3d896ffb9c1fe01c0  
3   Experienced (Non\PYGZhy{}Manager)  58435fcab804439efdcaa7ecca0fd783  
4  Project/Program Management  64d0272dc8496abfd9523a8df63c184c  
\end{sphinxVerbatim}

\sphinxAtStartPar
Need some inspiration? perhaps \sphinxhref{https://www.kaggle.com/ankkur13/perfect-dataset-to-get-the-hands-dirty}{this} might work.


\part{3. Data Preprocessing}


\chapter{Data Preprocessing}
\label{\detokenize{c3_data_preprocessing/introduction:data-preprocessing}}\label{\detokenize{c3_data_preprocessing/introduction::doc}}
\sphinxAtStartPar
this is an introduction


\part{4. Data Exploration}


\chapter{Data Exploration}
\label{\detokenize{c4_data_exploration/introduction:data-exploration}}\label{\detokenize{c4_data_exploration/introduction::doc}}
\sphinxAtStartPar
this is an introduction


\part{5. Data Visualisation}


\chapter{Data Visualisation}
\label{\detokenize{c5_data_visualisation/introduction:data-visualisation}}\label{\detokenize{c5_data_visualisation/introduction::doc}}
\sphinxAtStartPar
this is an introduction


\part{6. Machine Learning}


\chapter{Machine Learning}
\label{\detokenize{c6_machine_learning/introduction:machine-learning}}\label{\detokenize{c6_machine_learning/introduction::doc}}
\sphinxAtStartPar
this is an introduction







\renewcommand{\indexname}{Index}
\printindex
\end{document}